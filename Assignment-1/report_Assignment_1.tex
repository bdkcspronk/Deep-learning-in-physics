\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{xcolor}
\usepackage[color=blue]{attachfile2}
\usepackage{hyperref}

\hypersetup{
    colorlinks=true,
    urlcolor=blue
}

\title{DLIP - Assignment 1: Training}
\author{Bradley Spronk - s2504758}
\date{\today}

\begin{document}
\maketitle

\section{Python data science refresher.}
\href{https://github.com/bdkcspronk/Computational-Physics/tree/main/3D%20Ising%20Model%20App}{Link of github repository to past python project} demonstrating I don't need the refresher.

\section{Tensorflow playground.}

\subsection*{Duarte Homework 1 Problem 4A: First, select a linear model with no hidden layers. For the features, select the two independent variables \(x1\)
and \(x2\). Can you fit the data with this linear model? Why or why not?}
It is not possible to fit the data with a linear model with only the features \(x1\) and \(x2\), because the data is not linearly separable.
Or in other words, we cannot draw a straight line that separates the two classes of points in the feature space defined by \(x1\) and \(x2\).

\subsection*{What happens if you add the feature \(x1x2\)?}
However, if we add the feature \(x1x2\), we can fit the data perfectly, because it allows us to capture the interaction between \(x1\) and \(x2\),
which is necessary to separate the classes.

We cant change the output neurons activation. For instance when there is no hidden layer and we choose the ReLU model (max(0,x)) the output still shows negative numbers.

\subsection*{Now, return the features to just \((x1, x2)\) and start adding hidden layers. What's the smallest neural network
(least number of layers and least number of neurons per layer) you can create that fits the training data
"perfectly" (i.e. a training loss 0.001)?}
I suppose we have to use a non-linear activation function in the hidden layer, otherwise we would just be fitting a linear model again.
With ReLU, a neural network with 1 hidden layer with 4 neurons is the smallest neural network that fits the training data perfectly (with a training loss of \(<= 0.001\)).
With tanh, a neural network with 1 hidden layer with 5 neurons is the smallest neural network that fits the training data perfectly.

\subsection*{What is the corresponding test loss?}

\subsection*{Detail your hyperparameter choices by providing a screenshot and the URL to your solution (the URL contains all your settings choices).}

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{playground1.png}
    \caption{Screenshot of the smallest neural network that fits the training data perfectly.}
\end{figure}

\subsection*{Duarte Homework 1: Problem 4B}

Navigate your web browser to the TensorFlow Playground \url{https://playground.tensorflow.org/#dataset=spiral&discretize=true}.
Select the spiral pattern for the data.

Using all the features available, find a solution that fits the training data.
What training and test error do you achieve?
Is this a low bias/high variance or high bias/low variance model?
How do you know?

Using only $(x_1, x_2)$, find a solution that fits the training data.
What training and test error do you achieve?
Is this a low bias/high variance or high bias/low variance model?
How do you know?

For both solutions, detail your hyperparameter choices by providing a screenshot and the URL to your solution (the URL contains all your settings choices).

\section{Training curves for polynomial regression.}

\subsection*{Question on Brightspace: A sustained increase in the training error with epochs is unusual and indicates some problem (e.g. too high learning rate.).
However, a sustained increase in training error as you increase the amount of training data is quite normal if the test error is high. (Why?)}

This is because when the training data is small the model can sort of memorize the test data (test error is high in this case).
When you increase the training data the training error will increase because now it has to learn to actually model the data well.

\subsection*{Duarte Homework 1 Problem 2C}

The dataset \texttt{bv\_data.csv} is provided and has a header denoting which columns correspond to which values. Using this dataset, plot learning curves for 1st-, 2nd-, 6th-, and 12th-degree polynomial regression (4 separate plots) by following these steps for each degree $d \in \{1, 2, 6, 12\}$:

\begin{enumerate}
	\item For each $N \in \{20, 25, 30, 35, \ldots, 100\}$:
	      \begin{enumerate}
		      \item Perform 5-fold Cross-validation on the first $N$ points in the dataset (setting aside the other points), computing the both the training and validation error for each fold.
		            \begin{itemize}
			            \item Use the mean squared error loss as the error function.
			            \item Use NumPy's \texttt{polyfit} method to perform the degree-$d$ polynomial regression and NumPy's \texttt{polyval} method to help compute the errors.
			                  (See the example code and \href{https://docs.scipy.org/doc/NumPy/reference/routines.polynomials.poly1d.html}{NumPy documentation} for details.)
			            \item When partitioning your data into folds, although in practice you should randomize your partitions, for the purposes of this set, simply divide the data into $K$ contiguous blocks.
		            \end{itemize}
		      \item Compute the average of the training and validation errors from the 5 folds.
	      \end{enumerate}
	\item Create a learning curve by plotting both the average training and validation error as functions of $N$.
\end{enumerate}

\subsection*{Duarte Homework 1 Problem 2D}
Based on the learning curves, which polynomial regression model (i.e. which degree polynomial) has the highest bias? How can you tell?

\subsection*{Duarte Homework 1 Problem 2E}
Which model has the highest variance? How can you tell?

\subsection{Duarte Homework 1 Problem 2F}
What does the learning curve of the quadratic model tell you about how much the model will improve if we had additional training points?

\subsection{Duarte Homework 1 Problem 2G}
Why is training error generally lower than validation error?

\subsection{Duarte Homework 1 Problem 2H}
Based on the learning curves, which model would you expect to perform best on some unseen data drawn from the same distribution as the training data, and why?

\section{Stochastic gradient descent for linear regression.}

\subsection*{Duarte Homework Problem 2 Problem 1A-I}

\textattachfile[color=blue]{code/Homework2-problem-1.ipynb}{Open .ipynb}

\end{document}
