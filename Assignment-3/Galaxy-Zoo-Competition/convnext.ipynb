{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galaxy Zoo 2: ConvNeXt Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries and Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T09:21:13.304314Z",
     "iopub.status.busy": "2026-02-24T09:21:13.303927Z",
     "iopub.status.idle": "2026-02-24T09:21:13.312457Z",
     "shell.execute_reply": "2026-02-24T09:21:13.311355Z",
     "shell.execute_reply.started": "2026-02-24T09:21:13.304270Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure, show\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.models import ConvNeXt_Tiny_Weights\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "import concurrent.futures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Image Preprocessing and Tensor Saving Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "def process_image(img_path_output_size):\n",
    "    img_path, output_dir, size = img_path_output_size\n",
    "    basename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    out_path = os.path.join(output_dir, f\"{basename}.pt\")\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    width, height = img.size\n",
    "    left, top, right, bottom = 20, 20, width - 20, height - 20\n",
    "    img_cropped = img.crop((left, top, right, bottom))\n",
    "    img_resized = img_cropped.resize(size, Image.LANCZOS)\n",
    "    tensor = transforms.ToTensor()(img_resized)\n",
    "    tensor = norm(tensor)\n",
    "    torch.save(tensor, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tensor_images_threaded(input_dir, output_dir, size=(224, 224), num_workers=4):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    image_files = glob.glob(os.path.join(input_dir, '*.jpg'))\n",
    "    print(f\"Found {len(image_files)} images.\")\n",
    "    args = [(img_path, output_dir, size) for img_path in image_files]\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        results = list(executor.map(process_image, args))\n",
    "    for res in results[:20]:\n",
    "        print(res)\n",
    "    print(f\"Finished saving tensors for {len(image_files)} images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset class creation\n",
    "Can handle both training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GalaxyZooTensorDataset(Dataset):\n",
    "    def __init__(self, csv_file, tensor_dir):\n",
    "        self.tensor_dir = tensor_dir\n",
    "        if csv_file is not None:\n",
    "            self.df = pd.read_csv(csv_file)\n",
    "            self.ids = self.df.iloc[:, 0].values\n",
    "            self.labels = self.df.iloc[:, 1:].values.astype(np.float32)\n",
    "            self.has_labels = True\n",
    "        else:\n",
    "            # For test set, infer IDs from tensor filenames\n",
    "            self.df = None\n",
    "            self.ids = [os.path.splitext(f)[0] for f in sorted(os.listdir(tensor_dir)) if f.endswith('.pt')]\n",
    "            self.has_labels = False\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        galaxy_id = int(self.ids[idx])\n",
    "        tensor_path = os.path.join(self.tensor_dir, f\"{galaxy_id}.pt\")\n",
    "        image = torch.load(tensor_path, weights_only=True)\n",
    "        if self.has_labels:\n",
    "            labels = self.labels[idx]\n",
    "            return image, labels\n",
    "        else:\n",
    "            return image, galaxy_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load training solutions and dataset\n",
    "csv_file = './training_solutions_rev1/training_solutions_rev1.csv'\n",
    "tensor_dir = './images_training_rev1/images_training_resized'\n",
    "dataset = GalaxyZooTensorDataset(csv_file, tensor_dir)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "full_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "# For validation, split a portion from the full dataset\n",
    "from torch.utils.data import random_split\n",
    "total = len(dataset)\n",
    "val_size = int(0.2 * total)\n",
    "train_size = total - val_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load and Modify ConvNeXt Model\n",
    "Load the ConvNeXt model, freeze all layers except the classifier, and modify the final layer to match the number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "convnext = models.convnext_tiny(weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1)\n",
    "num_classes = dataset.labels.shape[1]\n",
    "\n",
    "# Freeze all parameters\n",
    "for param in convnext.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final layer\n",
    "in_features = convnext.classifier[2].in_features\n",
    "convnext.classifier[2] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "# Unfreeze only the last layer of the classifier\n",
    "for param in convnext.classifier[2].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "convnext = convnext.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Set Up Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, convnext.parameters()), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "convnext = convnext.to(device)\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload a checkpointed model\n",
    "if os.path.exists(\"checkpoint_last_layer.pth\"):\n",
    "    checkpoint = torch.load(\"checkpoint_last_layer.pth\")\n",
    "    convnext.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion, device, num_epochs=12):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        epoch_start = time.time()\n",
    "        for batch_idx, (images, labels) in enumerate(loader):\n",
    "            batch_start = time.time()\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            if (batch_idx + 1) % 30 == 0:\n",
    "                batch_time = time.time() - batch_start\n",
    "                print(f\"  Batch {batch_idx+1}/{len(loader)}: Loss={loss.item():.4f}, Batch Time={batch_time:.2f}s\")\n",
    "        avg_loss = running_loss / len(loader.dataset)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}: Loss={avg_loss:.4f}, Time={time.time()-epoch_start:.2f}s\")\n",
    "        losses.append(avg_loss)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Model Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, train_losses, filename):\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_losses': train_losses\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "    print(f\"Checkpoint saved as {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 30/482: Loss=0.3344, Batch Time=3.74s\n",
      "  Batch 60/482: Loss=0.3292, Batch Time=3.60s\n",
      "  Batch 90/482: Loss=0.3145, Batch Time=3.32s\n",
      "  Batch 120/482: Loss=0.2944, Batch Time=4.39s\n",
      "  Batch 150/482: Loss=0.2998, Batch Time=4.21s\n",
      "  Batch 180/482: Loss=0.2885, Batch Time=2.66s\n",
      "  Batch 210/482: Loss=0.3007, Batch Time=3.10s\n",
      "  Batch 240/482: Loss=0.2976, Batch Time=3.61s\n"
     ]
    }
   ],
   "source": [
    "file_name = \"normal\"\n",
    "train_losses = train(convnext, full_loader, optimizer, criterion, device, num_epochs=20)\n",
    "save_checkpoint(convnext, optimizer, train_losses, f\"checkpoint_{file_name}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint(convnext, optimizer, train_losses, f\"checkpoint_{file_name}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = pd.DataFrame({'epoch': list(range(1, len(train_losses)+1)), 'loss': train_losses})\n",
    "loss_df.to_csv('train_losses.csv', index=False)\n",
    "print('Training losses saved to train_losses.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluate Model on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnext.eval()\n",
    "val_losses = []\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        outputs = convnext(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_losses.append(loss.item() * images.size(0))\n",
    "        preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "        all_targets.append(labels.cpu().numpy())\n",
    "\n",
    "val_loss = np.sum(val_losses) / len(val_loader.dataset)\n",
    "all_preds = np.concatenate(all_preds, axis=0)\n",
    "all_targets = np.concatenate(all_targets, axis=0)\n",
    "\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "rmse = np.sqrt(np.mean((all_preds - all_targets) ** 2))\n",
    "print(f\"Validation RMSE: {rmse:.4f}\")\n",
    "\n",
    "np.savez('val_predictions.npz', preds=all_preds, targets=all_targets)\n",
    "print('Validation predictions and targets saved to val_predictions.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Evaluate on test dataset and save submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = GalaxyZooTensorDataset(csv_dir=None, tensor_dir='./images_test_rev1/images_test_resized')\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "convnext.eval()\n",
    "all_predictions = []\n",
    "all_galaxy_ids = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, galaxy_ids in test_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        outputs = convnext(images)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        all_predictions.append(probs.cpu().numpy())\n",
    "        all_galaxy_ids.extend(galaxy_ids)\n",
    "\n",
    "predictions = np.concatenate(all_predictions, axis=0)\n",
    "\n",
    "columns = ['GalaxyId']\n",
    "questions = {1: 3, 2: 2, 3: 2, 4: 2, 5: 4, 6: 2, 7: 3, 8: 7, 9: 3, 10: 3, 11: 6}\n",
    "for q, count in questions.items():\n",
    "    for i in range(1, count + 1):\n",
    "        columns.append(f'Class{q}.{i}')\n",
    "\n",
    "submission_df = pd.DataFrame(predictions, columns=columns[1:])\n",
    "submission_df.insert(0, 'GalaxyId', all_galaxy_ids)\n",
    "print(submission_df.head())\n",
    "submission_df.to_csv('submission_normal.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 44352,
     "sourceId": 3175,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 11163856,
     "datasetId": 6706770,
     "sourceId": 10805162,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "tfdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
