{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d7e1ed6",
   "metadata": {},
   "source": [
    "# Galaxy Zoo 2: ConvNeXt Transfer Learning\n",
    "\n",
    "This notebook demonstrates transfer learning for the Galaxy Zoo 2 dataset using PyTorch and ConvNeXt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f659c6f",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries and Utilities\n",
    "Import all necessary libraries, including torch, torchvision, numpy, pandas, matplotlib, and any utility functions/classes reused from the original notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edc047fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T09:39:08.441980Z",
     "iopub.status.busy": "2026-02-27T09:39:08.441680Z",
     "iopub.status.idle": "2026-02-27T09:39:08.449369Z",
     "shell.execute_reply": "2026-02-27T09:39:08.448415Z",
     "shell.execute_reply.started": "2026-02-27T09:39:08.441950Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "import concurrent.futures\n",
    "from torchvision.models import ConvNeXt_Small_Weights\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "191bc735-afad-4695-b96a-fdab8e85eac7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T09:39:08.451048Z",
     "iopub.status.busy": "2026-02-27T09:39:08.450796Z",
     "iopub.status.idle": "2026-02-27T09:39:41.144914Z",
     "shell.execute_reply": "2026-02-27T09:39:41.144092Z",
     "shell.execute_reply.started": "2026-02-27T09:39:08.450994Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "def unzip_file(zip_path, extract_to):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "base_path = \"/kaggle/input/competitions/galaxy-zoo-the-galaxy-challenge\"\n",
    "output_path = \"/kaggle/working/galaxy_zoo\"\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "unzip_file(f\"{base_path}/images_training_rev1.zip\", output_path)\n",
    "unzip_file(f\"{base_path}/images_test_rev1.zip\", output_path)\n",
    "unzip_file(f\"{base_path}/training_solutions_rev1.zip\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "115b08ce-80da-4ce8-a6d2-d653fd2de30e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T09:39:41.145948Z",
     "iopub.status.busy": "2026-02-27T09:39:41.145696Z",
     "iopub.status.idle": "2026-02-27T09:39:41.150630Z",
     "shell.execute_reply": "2026-02-27T09:39:41.149864Z",
     "shell.execute_reply.started": "2026-02-27T09:39:41.145926Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.CenterCrop(384),   # replaces manual crop\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd76db",
   "metadata": {},
   "source": [
    "## 3. Define GalaxyZooTensorDataset Class\n",
    "Reuse the GalaxyZooTensorDataset class for loading preprocessed tensor images and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc42f218",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T09:39:41.152747Z",
     "iopub.status.busy": "2026-02-27T09:39:41.152536Z",
     "iopub.status.idle": "2026-02-27T09:39:41.164585Z",
     "shell.execute_reply": "2026-02-27T09:39:41.163881Z",
     "shell.execute_reply.started": "2026-02-27T09:39:41.152728Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GalaxyZooImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        if csv_file is not None:\n",
    "            self.df = pd.read_csv(csv_file)\n",
    "            self.ids = self.df.iloc[:, 0].values\n",
    "            self.labels = self.df.iloc[:, 1:].values.astype(np.float32)\n",
    "            self.has_labels = True\n",
    "        else:\n",
    "            self.df = None\n",
    "            self.ids = [\n",
    "                os.path.splitext(f)[0]\n",
    "                for f in os.listdir(image_dir)\n",
    "                if f.endswith(\".jpg\")\n",
    "            ]\n",
    "            self.labels = None\n",
    "            self.has_labels = False\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        galaxy_id = self.ids[idx]\n",
    "        img_path = os.path.join(self.image_dir, f\"{galaxy_id}.jpg\")\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.has_labels:\n",
    "            label = torch.tensor(self.labels[idx])\n",
    "            return image, label\n",
    "        else:\n",
    "            return image, galaxy_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425e4d2b",
   "metadata": {},
   "source": [
    "## 4. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "247c9013",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T09:39:41.165629Z",
     "iopub.status.busy": "2026-02-27T09:39:41.165391Z",
     "iopub.status.idle": "2026-02-27T09:39:41.419665Z",
     "shell.execute_reply": "2026-02-27T09:39:41.419068Z",
     "shell.execute_reply.started": "2026-02-27T09:39:41.165610Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load training solutions and dataset\n",
    "csv_file = '/kaggle/working/galaxy_zoo/training_solutions_rev1.csv'\n",
    "image_dir = '/kaggle/working/galaxy_zoo/images_training_rev1'\n",
    "dataset = GalaxyZooImageDataset(csv_file, image_dir, transform=train_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a733c0e6",
   "metadata": {},
   "source": [
    "## 5. Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9eb57d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T09:39:41.421482Z",
     "iopub.status.busy": "2026-02-27T09:39:41.420702Z",
     "iopub.status.idle": "2026-02-27T09:39:41.425153Z",
     "shell.execute_reply": "2026-02-27T09:39:41.424486Z",
     "shell.execute_reply.started": "2026-02-27T09:39:41.421446Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "full_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60b2f39",
   "metadata": {},
   "source": [
    "## 6. Load and Modify ConvNeXt Model\n",
    "Load the ConvNeXt model, freeze all layers except the classifier, and modify the final layer to match the number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7df0233",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T09:39:41.426418Z",
     "iopub.status.busy": "2026-02-27T09:39:41.426199Z",
     "iopub.status.idle": "2026-02-27T09:39:42.415826Z",
     "shell.execute_reply": "2026-02-27T09:39:42.415267Z",
     "shell.execute_reply.started": "2026-02-27T09:39:41.426397Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "convnext = models.convnext_small(weights=ConvNeXt_Small_Weights.IMAGENET1K_V1)\n",
    "num_classes = dataset.labels.shape[1]\n",
    "\n",
    "# Freeze everything first\n",
    "for param in convnext.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final classifier layer\n",
    "in_features = convnext.classifier[2].in_features\n",
    "convnext.classifier[2] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "# Unfreeze last two feature stages and classifier, collect params for optimizer\n",
    "backbone_params = []\n",
    "classifier_params = []\n",
    "\n",
    "for stage in convnext.features[-2:]:\n",
    "    for param in stage.parameters():\n",
    "        param.requires_grad = True\n",
    "        backbone_params.append(param)\n",
    "\n",
    "for param in convnext.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "    classifier_params.append(param)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "convnext = convnext.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13479e4",
   "metadata": {},
   "source": [
    "## 7. Set Up Loss Function and Optimizer\n",
    "Set up the BCEWithLogitsLoss and Adam optimizer, filtering parameters as in the original notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22470481",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T09:39:42.422532Z",
     "iopub.status.busy": "2026-02-27T09:39:42.422218Z",
     "iopub.status.idle": "2026-02-27T09:39:42.433213Z",
     "shell.execute_reply": "2026-02-27T09:39:42.432519Z",
     "shell.execute_reply.started": "2026-02-27T09:39:42.422496Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [\n",
    "        {\"params\": backbone_params, \"lr\": 1e-4},\n",
    "        {\"params\": classifier_params, \"lr\": 1e-3},\n",
    "    ],\n",
    "    weight_decay=1e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378a073c",
   "metadata": {},
   "source": [
    "## 8. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcfea4e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T09:39:42.435551Z",
     "iopub.status.busy": "2026-02-27T09:39:42.435141Z",
     "iopub.status.idle": "2026-02-27T09:39:42.448217Z",
     "shell.execute_reply": "2026-02-27T09:39:42.447512Z",
     "shell.execute_reply.started": "2026-02-27T09:39:42.435529Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_one_stage(model, loader, optimizer, criterion, device, num_epochs=20, stage_name=\"Stage\"):\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        for batch_idx, (images, labels) in enumerate(loader):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            # Debug every 30 batches\n",
    "            if (batch_idx + 1) % 30 == 0:\n",
    "                current_avg = running_loss / ((batch_idx + 1) * loader.batch_size)\n",
    "                print(\n",
    "                    f\"{stage_name} Epoch {epoch+1}/{num_epochs} \"\n",
    "                    f\"Batch {batch_idx+1}/{len(loader)} \"\n",
    "                    f\"Loss={loss.item():.4f} \"\n",
    "                    f\"RunningAvg={current_avg:.4f}\"\n",
    "                )\n",
    "\n",
    "        avg_loss = running_loss / len(loader.dataset)\n",
    "        losses.append(avg_loss)\n",
    "\n",
    "        print(\n",
    "            f\"{stage_name} Epoch {epoch+1}/{num_epochs}: \"\n",
    "            f\"Loss={avg_loss:.4f}, \"\n",
    "            f\"Time={time.time()-epoch_start:.2f}s\"\n",
    "        )\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2bc55e",
   "metadata": {},
   "source": [
    "## 9. Save Model Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fff9f4b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T09:39:42.449322Z",
     "iopub.status.busy": "2026-02-27T09:39:42.449004Z",
     "iopub.status.idle": "2026-02-27T09:39:42.461043Z",
     "shell.execute_reply": "2026-02-27T09:39:42.460394Z",
     "shell.execute_reply.started": "2026-02-27T09:39:42.449294Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, train_losses, filename):\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_losses': train_losses\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "    print(f\"Checkpoint saved as {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98907160",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T09:39:42.462277Z",
     "iopub.status.busy": "2026-02-27T09:39:42.461913Z",
     "iopub.status.idle": "2026-02-27T09:39:42.471489Z",
     "shell.execute_reply": "2026-02-27T09:39:42.470753Z",
     "shell.execute_reply.started": "2026-02-27T09:39:42.462245Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bf45e81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T09:39:42.472972Z",
     "iopub.status.busy": "2026-02-27T09:39:42.472481Z",
     "iopub.status.idle": "2026-02-27T11:33:25.947455Z",
     "shell.execute_reply": "2026-02-27T11:33:25.946589Z",
     "shell.execute_reply.started": "2026-02-27T09:39:42.472951Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_layer Epoch 1/20 Batch 30/121 Loss=0.2855 RunningAvg=0.3302\n",
      "2_layer Epoch 1/20 Batch 60/121 Loss=0.2605 RunningAvg=0.3014\n",
      "2_layer Epoch 1/20 Batch 90/121 Loss=0.2613 RunningAvg=0.2889\n",
      "2_layer Epoch 1/20 Batch 120/121 Loss=0.2595 RunningAvg=0.2814\n",
      "2_layer Epoch 1/20: Loss=0.2814, Time=341.34s\n",
      "2_layer Epoch 2/20 Batch 30/121 Loss=0.2586 RunningAvg=0.2572\n",
      "2_layer Epoch 2/20 Batch 60/121 Loss=0.2545 RunningAvg=0.2556\n",
      "2_layer Epoch 2/20 Batch 90/121 Loss=0.2563 RunningAvg=0.2551\n",
      "2_layer Epoch 2/20 Batch 120/121 Loss=0.2488 RunningAvg=0.2542\n",
      "2_layer Epoch 2/20: Loss=0.2542, Time=340.98s\n",
      "2_layer Epoch 3/20 Batch 30/121 Loss=0.2526 RunningAvg=0.2512\n",
      "2_layer Epoch 3/20 Batch 60/121 Loss=0.2480 RunningAvg=0.2508\n",
      "2_layer Epoch 3/20 Batch 90/121 Loss=0.2512 RunningAvg=0.2506\n",
      "2_layer Epoch 3/20 Batch 120/121 Loss=0.2481 RunningAvg=0.2504\n",
      "2_layer Epoch 3/20: Loss=0.2504, Time=341.21s\n",
      "2_layer Epoch 4/20 Batch 30/121 Loss=0.2502 RunningAvg=0.2492\n",
      "2_layer Epoch 4/20 Batch 60/121 Loss=0.2496 RunningAvg=0.2488\n",
      "2_layer Epoch 4/20 Batch 90/121 Loss=0.2479 RunningAvg=0.2487\n",
      "2_layer Epoch 4/20 Batch 120/121 Loss=0.2515 RunningAvg=0.2484\n",
      "2_layer Epoch 4/20: Loss=0.2484, Time=341.12s\n",
      "2_layer Epoch 5/20 Batch 30/121 Loss=0.2442 RunningAvg=0.2472\n",
      "2_layer Epoch 5/20 Batch 60/121 Loss=0.2454 RunningAvg=0.2478\n",
      "2_layer Epoch 5/20 Batch 90/121 Loss=0.2381 RunningAvg=0.2474\n",
      "2_layer Epoch 5/20 Batch 120/121 Loss=0.2425 RunningAvg=0.2473\n",
      "2_layer Epoch 5/20: Loss=0.2473, Time=341.10s\n",
      "2_layer Epoch 6/20 Batch 30/121 Loss=0.2508 RunningAvg=0.2462\n",
      "2_layer Epoch 6/20 Batch 60/121 Loss=0.2406 RunningAvg=0.2459\n",
      "2_layer Epoch 6/20 Batch 90/121 Loss=0.2446 RunningAvg=0.2462\n",
      "2_layer Epoch 6/20 Batch 120/121 Loss=0.2423 RunningAvg=0.2461\n",
      "2_layer Epoch 6/20: Loss=0.2462, Time=341.48s\n",
      "2_layer Epoch 7/20 Batch 30/121 Loss=0.2522 RunningAvg=0.2452\n",
      "2_layer Epoch 7/20 Batch 60/121 Loss=0.2459 RunningAvg=0.2456\n",
      "2_layer Epoch 7/20 Batch 90/121 Loss=0.2364 RunningAvg=0.2454\n",
      "2_layer Epoch 7/20 Batch 120/121 Loss=0.2459 RunningAvg=0.2453\n",
      "2_layer Epoch 7/20: Loss=0.2453, Time=341.27s\n",
      "2_layer Epoch 8/20 Batch 30/121 Loss=0.2449 RunningAvg=0.2452\n",
      "2_layer Epoch 8/20 Batch 60/121 Loss=0.2462 RunningAvg=0.2447\n",
      "2_layer Epoch 8/20 Batch 90/121 Loss=0.2408 RunningAvg=0.2445\n",
      "2_layer Epoch 8/20 Batch 120/121 Loss=0.2445 RunningAvg=0.2447\n",
      "2_layer Epoch 8/20: Loss=0.2447, Time=341.10s\n",
      "2_layer Epoch 9/20 Batch 30/121 Loss=0.2378 RunningAvg=0.2442\n",
      "2_layer Epoch 9/20 Batch 60/121 Loss=0.2437 RunningAvg=0.2442\n",
      "2_layer Epoch 9/20 Batch 90/121 Loss=0.2415 RunningAvg=0.2440\n",
      "2_layer Epoch 9/20 Batch 120/121 Loss=0.2471 RunningAvg=0.2440\n",
      "2_layer Epoch 9/20: Loss=0.2441, Time=341.62s\n",
      "2_layer Epoch 10/20 Batch 30/121 Loss=0.2455 RunningAvg=0.2429\n",
      "2_layer Epoch 10/20 Batch 60/121 Loss=0.2428 RunningAvg=0.2434\n",
      "2_layer Epoch 10/20 Batch 90/121 Loss=0.2470 RunningAvg=0.2432\n",
      "2_layer Epoch 10/20 Batch 120/121 Loss=0.2441 RunningAvg=0.2436\n",
      "2_layer Epoch 10/20: Loss=0.2436, Time=340.31s\n",
      "2_layer Epoch 11/20 Batch 30/121 Loss=0.2433 RunningAvg=0.2420\n",
      "2_layer Epoch 11/20 Batch 60/121 Loss=0.2416 RunningAvg=0.2426\n",
      "2_layer Epoch 11/20 Batch 90/121 Loss=0.2453 RunningAvg=0.2428\n",
      "2_layer Epoch 11/20 Batch 120/121 Loss=0.2453 RunningAvg=0.2431\n",
      "2_layer Epoch 11/20: Loss=0.2431, Time=340.40s\n",
      "2_layer Epoch 12/20 Batch 30/121 Loss=0.2419 RunningAvg=0.2427\n",
      "2_layer Epoch 12/20 Batch 60/121 Loss=0.2413 RunningAvg=0.2427\n",
      "2_layer Epoch 12/20 Batch 90/121 Loss=0.2453 RunningAvg=0.2427\n",
      "2_layer Epoch 12/20 Batch 120/121 Loss=0.2498 RunningAvg=0.2427\n",
      "2_layer Epoch 12/20: Loss=0.2427, Time=340.95s\n",
      "2_layer Epoch 13/20 Batch 30/121 Loss=0.2431 RunningAvg=0.2418\n",
      "2_layer Epoch 13/20 Batch 60/121 Loss=0.2377 RunningAvg=0.2425\n",
      "2_layer Epoch 13/20 Batch 90/121 Loss=0.2418 RunningAvg=0.2423\n",
      "2_layer Epoch 13/20 Batch 120/121 Loss=0.2471 RunningAvg=0.2423\n",
      "2_layer Epoch 13/20: Loss=0.2423, Time=341.40s\n",
      "2_layer Epoch 14/20 Batch 30/121 Loss=0.2398 RunningAvg=0.2409\n",
      "2_layer Epoch 14/20 Batch 60/121 Loss=0.2459 RunningAvg=0.2416\n",
      "2_layer Epoch 14/20 Batch 90/121 Loss=0.2400 RunningAvg=0.2418\n",
      "2_layer Epoch 14/20 Batch 120/121 Loss=0.2386 RunningAvg=0.2419\n",
      "2_layer Epoch 14/20: Loss=0.2419, Time=341.27s\n",
      "2_layer Epoch 15/20 Batch 30/121 Loss=0.2427 RunningAvg=0.2414\n",
      "2_layer Epoch 15/20 Batch 60/121 Loss=0.2433 RunningAvg=0.2415\n",
      "2_layer Epoch 15/20 Batch 90/121 Loss=0.2461 RunningAvg=0.2418\n",
      "2_layer Epoch 15/20 Batch 120/121 Loss=0.2418 RunningAvg=0.2415\n",
      "2_layer Epoch 15/20: Loss=0.2415, Time=341.59s\n",
      "2_layer Epoch 16/20 Batch 30/121 Loss=0.2450 RunningAvg=0.2414\n",
      "2_layer Epoch 16/20 Batch 60/121 Loss=0.2357 RunningAvg=0.2408\n",
      "2_layer Epoch 16/20 Batch 90/121 Loss=0.2457 RunningAvg=0.2407\n",
      "2_layer Epoch 16/20 Batch 120/121 Loss=0.2370 RunningAvg=0.2412\n",
      "2_layer Epoch 16/20: Loss=0.2412, Time=341.80s\n",
      "2_layer Epoch 17/20 Batch 30/121 Loss=0.2417 RunningAvg=0.2406\n",
      "2_layer Epoch 17/20 Batch 60/121 Loss=0.2469 RunningAvg=0.2408\n",
      "2_layer Epoch 17/20 Batch 90/121 Loss=0.2407 RunningAvg=0.2411\n",
      "2_layer Epoch 17/20 Batch 120/121 Loss=0.2405 RunningAvg=0.2409\n",
      "2_layer Epoch 17/20: Loss=0.2409, Time=340.85s\n",
      "2_layer Epoch 18/20 Batch 30/121 Loss=0.2427 RunningAvg=0.2407\n",
      "2_layer Epoch 18/20 Batch 60/121 Loss=0.2438 RunningAvg=0.2404\n",
      "2_layer Epoch 18/20 Batch 90/121 Loss=0.2436 RunningAvg=0.2403\n",
      "2_layer Epoch 18/20 Batch 120/121 Loss=0.2470 RunningAvg=0.2405\n",
      "2_layer Epoch 18/20: Loss=0.2405, Time=341.17s\n",
      "2_layer Epoch 19/20 Batch 30/121 Loss=0.2420 RunningAvg=0.2403\n",
      "2_layer Epoch 19/20 Batch 60/121 Loss=0.2369 RunningAvg=0.2400\n",
      "2_layer Epoch 19/20 Batch 90/121 Loss=0.2421 RunningAvg=0.2402\n",
      "2_layer Epoch 19/20 Batch 120/121 Loss=0.2385 RunningAvg=0.2403\n",
      "2_layer Epoch 19/20: Loss=0.2403, Time=340.90s\n",
      "2_layer Epoch 20/20 Batch 30/121 Loss=0.2410 RunningAvg=0.2400\n",
      "2_layer Epoch 20/20 Batch 60/121 Loss=0.2403 RunningAvg=0.2398\n",
      "2_layer Epoch 20/20 Batch 90/121 Loss=0.2413 RunningAvg=0.2399\n",
      "2_layer Epoch 20/20 Batch 120/121 Loss=0.2421 RunningAvg=0.2400\n",
      "2_layer Epoch 20/20: Loss=0.2400, Time=341.03s\n",
      "Checkpoint saved as checkpoint_2_layer.pth\n"
     ]
    }
   ],
   "source": [
    "stage_name = \"2_layer\"\n",
    "losses = train_one_stage(convnext, full_loader, optimizer, criterion, device, num_epochs=20, stage_name=stage_name)\n",
    "save_checkpoint(convnext, optimizer, losses, f\"checkpoint_{stage_name}.pth\")\n",
    "train_losses.extend(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f18934c",
   "metadata": {},
   "source": [
    "## 10. Save Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7ec9416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T11:33:25.948984Z",
     "iopub.status.busy": "2026-02-27T11:33:25.948755Z",
     "iopub.status.idle": "2026-02-27T11:33:25.983417Z",
     "shell.execute_reply": "2026-02-27T11:33:25.982772Z",
     "shell.execute_reply.started": "2026-02-27T11:33:25.948960Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training losses saved to train_losses_2_layer.csv\n"
     ]
    }
   ],
   "source": [
    "loss_df = pd.DataFrame({'epoch': list(range(1, len(losses)+1)), 'loss': losses})\n",
    "loss_df.to_csv('train_losses_2_layer.csv', index=False)\n",
    "print('Training losses saved to train_losses_2_layer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ef8e2c",
   "metadata": {},
   "source": [
    "## 11. Evaluate on test dataset and save submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e14055e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T11:33:25.984604Z",
     "iopub.status.busy": "2026-02-27T11:33:25.984344Z",
     "iopub.status.idle": "2026-02-27T11:39:11.878226Z",
     "shell.execute_reply": "2026-02-27T11:39:11.877535Z",
     "shell.execute_reply.started": "2026-02-27T11:33:25.984582Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GalaxyId  Class1.1  Class1.2  Class1.3  Class2.1  Class2.2  Class3.1  \\\n",
      "0   330879  0.813227  0.131761  0.049507  0.007043  0.120720  0.005384   \n",
      "1   488101  0.068476  0.926639  0.006073  0.043621  0.892778  0.059002   \n",
      "2   250283  0.416989  0.568959  0.006695  0.540014  0.097956  0.026330   \n",
      "3   674086  0.687720  0.266575  0.054557  0.008842  0.232478  0.013878   \n",
      "4   978686  0.523805  0.434150  0.035505  0.012733  0.379234  0.073247   \n",
      "\n",
      "   Class3.2  Class4.1  Class4.2  ...  Class9.3  Class10.1  Class10.2  \\\n",
      "0  0.115147  0.006579  0.118242  ...  0.000440   0.002269   0.002022   \n",
      "1  0.848857  0.847676  0.066704  ...  0.016094   0.640775   0.301475   \n",
      "2  0.073546  0.020657  0.091587  ...  0.045186   0.010986   0.004896   \n",
      "3  0.299039  0.032044  0.254406  ...  0.000747   0.022740   0.011810   \n",
      "4  0.257033  0.036286  0.373198  ...  0.001039   0.015428   0.016188   \n",
      "\n",
      "   Class10.3  Class11.1  Class11.2  Class11.3  Class11.4  Class11.5  Class11.6  \n",
      "0   0.001970   0.000581   0.001117   0.000121   0.000090   0.000548   0.004091  \n",
      "1   0.030069   0.018315   0.166348   0.114499   0.064391   0.131802   0.429292  \n",
      "2   0.005475   0.000820   0.006657   0.000172   0.000181   0.000552   0.013598  \n",
      "3   0.004322   0.008367   0.005242   0.000989   0.000310   0.001793   0.035874  \n",
      "4   0.006899   0.007676   0.013576   0.000762   0.000359   0.000890   0.016691  \n",
      "\n",
      "[5 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = GalaxyZooImageDataset(\n",
    "    csv_file=None,\n",
    "    image_dir='/kaggle/working/galaxy_zoo/images_test_rev1',\n",
    "    transform=train_transform\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "convnext.eval()\n",
    "all_predictions = []\n",
    "all_galaxy_ids = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, galaxy_ids in test_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        outputs = convnext(images)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        all_predictions.append(probs.cpu().numpy())\n",
    "        all_galaxy_ids.extend(galaxy_ids)\n",
    "\n",
    "predictions = np.concatenate(all_predictions, axis=0)\n",
    "\n",
    "columns = ['GalaxyId']\n",
    "questions = {1: 3, 2: 2, 3: 2, 4: 2, 5: 4, 6: 2, 7: 3, 8: 7, 9: 3, 10: 3, 11: 6}\n",
    "for q, count in questions.items():\n",
    "    for i in range(1, count + 1):\n",
    "        columns.append(f'Class{q}.{i}')\n",
    "\n",
    "submission_df = pd.DataFrame(predictions, columns=columns[1:])\n",
    "submission_df.insert(0, 'GalaxyId', all_galaxy_ids)\n",
    "print(submission_df.head())\n",
    "submission_df.to_csv('submission_2_layer.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 44352,
     "sourceId": 3175,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31286,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
