{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d7e1ed6",
   "metadata": {},
   "source": [
    "# Galaxy Zoo 2: ConvNeXt Curriculum Learning\n",
    "\n",
    "This notebook demonstrates curriculum learning for the Galaxy Zoo 2 dataset using PyTorch and ConvNeXt. We reuse functions and classes from the original ConvNeXt notebook and implement a staged training process where the model is first trained on high-confidence examples, then gradually exposed to more ambiguous data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f659c6f",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries and Utilities\n",
    "Import all necessary libraries, including torch, torchvision, numpy, pandas, matplotlib, and any utility functions/classes reused from the original notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc047fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "import concurrent.futures\n",
    "from torchvision.models import ConvNeXt_Tiny_Weights\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8402e71a",
   "metadata": {},
   "source": [
    "## 2. Define Image Preprocessing and Tensor Saving Functions\n",
    "Reuse the image preprocessing and tensor saving functions from the original notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857b0eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "def process_image(img_path_output_size):\n",
    "    img_path, output_dir, size = img_path_output_size\n",
    "    basename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    out_path = os.path.join(output_dir, f\"{basename}.pt\")\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    width, height = img.size\n",
    "    left, top, right, bottom = 20, 20, width - 20, height - 20\n",
    "    img_cropped = img.crop((left, top, right, bottom))\n",
    "    img_resized = img_cropped.resize(size, Image.LANCZOS)\n",
    "    tensor = transforms.ToTensor()(img_resized)\n",
    "    tensor = norm(tensor)\n",
    "    torch.save(tensor, out_path)\n",
    "\n",
    "def save_tensor_images_threaded(input_dir, output_dir, size=(224, 224), num_workers=4):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    image_files = glob.glob(os.path.join(input_dir, '*.jpg'))\n",
    "    print(f\"Found {len(image_files)} images.\")\n",
    "    args = [(img_path, output_dir, size) for img_path in image_files]\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        results = list(executor.map(process_image, args))\n",
    "    for res in results[:20]:\n",
    "        print(res)\n",
    "    print(f\"Finished saving tensors for {len(image_files)} images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd76db",
   "metadata": {},
   "source": [
    "## 3. Define GalaxyZooTensorDataset Class\n",
    "Reuse the GalaxyZooTensorDataset class for loading preprocessed tensor images and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc42f218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GalaxyZooTensorDataset(Dataset):\n",
    "    def __init__(self, csv_file, tensor_dir):\n",
    "        self.tensor_dir = tensor_dir\n",
    "        if csv_file is not None:\n",
    "            self.df = pd.read_csv(csv_file)\n",
    "            self.ids = self.df.iloc[:, 0].values\n",
    "            self.labels = self.df.iloc[:, 1:].values.astype(np.float32)\n",
    "            self.has_labels = True\n",
    "        else:\n",
    "            # For test set, infer IDs from tensor filenames\n",
    "            self.df = None\n",
    "            self.ids = [os.path.splitext(f)[0] for f in sorted(os.listdir(tensor_dir)) if f.endswith('.pt')]\n",
    "            self.has_labels = False\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        galaxy_id = int(self.ids[idx])\n",
    "        tensor_path = os.path.join(self.tensor_dir, f\"{galaxy_id}.pt\")\n",
    "        image = torch.load(tensor_path, weights_only=True)\n",
    "        if self.has_labels:\n",
    "            labels = self.labels[idx]\n",
    "            return image, labels\n",
    "        else:\n",
    "            return image, galaxy_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425e4d2b",
   "metadata": {},
   "source": [
    "## 4. Prepare Curriculum Learning Data Splits\n",
    "We will split the training data into curriculum stages based on label confidence (maximum probability per sample). High-confidence samples will be used first, followed by medium and low-confidence samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247c9013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training solutions and dataset\n",
    "csv_file = './training_solutions_rev1/training_solutions_rev1.csv'\n",
    "tensor_dir = './images_training_rev1/images_training_resized'\n",
    "dataset = GalaxyZooTensorDataset(csv_file, tensor_dir)\n",
    "\n",
    "# Compute confidence (max probability) for each sample\n",
    "confidences = dataset.labels.max(axis=1)\n",
    "\n",
    "# Define thresholds for curriculum stages\n",
    "high_thresh = 0.94\n",
    "med_thresh = 0.85\n",
    "\n",
    "high_conf_idx = np.where(confidences >= high_thresh)[0]\n",
    "med_conf_idx = np.where((confidences < high_thresh) & (confidences >= med_thresh))[0]\n",
    "low_conf_idx = np.where(confidences < med_thresh)[0]\n",
    "\n",
    "print(f\"High confidence: {len(high_conf_idx)} samples\")\n",
    "print(f\"Medium confidence: {len(med_conf_idx)} samples\")\n",
    "print(f\"Low confidence: {len(low_conf_idx)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a733c0e6",
   "metadata": {},
   "source": [
    "## 5. Create DataLoaders for Curriculum Stages\n",
    "Create DataLoaders for each curriculum stage using the corresponding subset of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9eb57d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "high_conf_loader = DataLoader(Subset(dataset, high_conf_idx), batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "med_conf_loader = DataLoader(Subset(dataset, np.concatenate([high_conf_idx, med_conf_idx])), batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "full_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "# For validation, split a portion from the full dataset\n",
    "from torch.utils.data import random_split\n",
    "total = len(dataset)\n",
    "val_size = int(0.2 * total)\n",
    "train_size = total - val_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60b2f39",
   "metadata": {},
   "source": [
    "## 6. Load and Modify ConvNeXt Model\n",
    "Load the ConvNeXt model, freeze all layers except the classifier, and modify the final layer to match the number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7df0233",
   "metadata": {},
   "outputs": [],
   "source": [
    "convnext = models.convnext_tiny(weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1)\n",
    "num_classes = dataset.labels.shape[1]\n",
    "\n",
    "# Freeze all parameters\n",
    "for param in convnext.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final layer\n",
    "in_features = convnext.classifier[2].in_features\n",
    "convnext.classifier[2] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "# Unfreeze only the last layer of the classifier\n",
    "for param in convnext.classifier[2].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "convnext = convnext.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13479e4",
   "metadata": {},
   "source": [
    "## 7. Set Up Loss Function and Optimizer\n",
    "Set up the BCEWithLogitsLoss and Adam optimizer, filtering parameters as in the original notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22470481",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, convnext.parameters()), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378a073c",
   "metadata": {},
   "source": [
    "## 8. Train Model with Curriculum Learning Loop\n",
    "Train the model sequentially on high-confidence, then medium, then all data. Track and print training loss for each stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfea4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_stage(model, loader, optimizer, criterion, device, num_epochs=3, stage_name=\"Stage\"):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        epoch_start = time.time()\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "        avg_loss = running_loss / len(loader.dataset)\n",
    "        losses.append(avg_loss)\n",
    "        print(f\"{stage_name} Epoch {epoch+1}/{num_epochs}: Loss={avg_loss:.4f}, Time={time.time()-epoch_start:.2f}s\")\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2bc55e",
   "metadata": {},
   "source": [
    "## 9. Save Model Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff9f4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, train_losses, filename):\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_losses': train_losses\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "    print(f\"Checkpoint saved as {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98907160",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf45e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training on high-confidence samples...\")\n",
    "stage_name = \"High_Confidence\"\n",
    "high_losses = train_one_stage(convnext, high_conf_loader, optimizer, criterion, device, num_epochs=5, stage_name=stage_name)\n",
    "save_checkpoint(convnext, optimizer, train_losses, f\"curriculum_checkpoint_{stage_name}.pth\")\n",
    "train_losses.extend(high_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bca3bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training on high+medium-confidence samples...\")\n",
    "stage_name = \"Medium_Confidence\"\n",
    "med_losses = train_one_stage(convnext, med_conf_loader, optimizer, criterion, device, num_epochs=5, stage_name=stage_name)\n",
    "save_checkpoint(convnext, optimizer, train_losses, f\"curriculum_checkpoint_{stage_name}.pth\")\n",
    "train_losses.extend(med_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d4ecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training on all samples...\")\n",
    "stage_name = \"All_data\"\n",
    "full_losses = train_one_stage(convnext, full_loader, optimizer, criterion, device, num_epochs=10, stage_name=stage_name)\n",
    "save_checkpoint(convnext, optimizer, train_losses, f\"curriculum_checkpoint_{stage_name}.pth\")\n",
    "train_losses.extend(full_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f18934c",
   "metadata": {},
   "source": [
    "## 10. Save Training Loss for Each Curriculum Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ec9416",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = pd.DataFrame({'epoch': list(range(1, len(train_losses)+1)), 'loss': train_losses})\n",
    "loss_df.to_csv('curriculum_train_losses.csv', index=False)\n",
    "print('Training losses saved to curriculum_train_losses.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120b903a",
   "metadata": {},
   "source": [
    "## 11. Evaluate Model on Validation Set\n",
    "After curriculum training, evaluate the model on the validation set and report relevant metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f48cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "convnext.eval()\n",
    "val_losses = []\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        outputs = convnext(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_losses.append(loss.item() * images.size(0))\n",
    "        preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "        all_targets.append(labels.cpu().numpy())\n",
    "\n",
    "val_loss = np.sum(val_losses) / len(val_loader.dataset)\n",
    "all_preds = np.concatenate(all_preds, axis=0)\n",
    "all_targets = np.concatenate(all_targets, axis=0)\n",
    "\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "rmse = np.sqrt(np.mean((all_preds - all_targets) ** 2))\n",
    "print(f\"Validation RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b5f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'checkpoint_curriculum_2_layers.pth'\n",
    "\n",
    "# Set up model with correct output size before loading checkpoint\n",
    "convnext = models.convnext_tiny(weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1)\n",
    "num_classes = 37  # or dataset.labels.shape[1] if available\n",
    "\n",
    "# Replace the final layer\n",
    "in_features = convnext.classifier[2].in_features\n",
    "convnext.classifier[2] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "convnext = convnext.to(device)\n",
    "\n",
    "# Now load the checkpoint\n",
    "checkpoint = torch.load(filename, map_location=device)\n",
    "convnext.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "train_losses = checkpoint['train_losses']\n",
    "print(f\"Loaded checkpoint from {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf41ab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fine-tune last half of layers after curriculum learning ---\n",
    "# Unfreeze only the last half of the model's parameters\n",
    "params = list(convnext.parameters())\n",
    "num_to_unfreeze = len(params) // 2\n",
    "for i, param in enumerate(params):\n",
    "    param.requires_grad = (i >= len(params) - num_to_unfreeze)\n",
    "\n",
    "# Use a much smaller learning rate for fine-tuning\n",
    "finetune_optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, convnext.parameters()), lr=1e-5)\n",
    "\n",
    "# Train for a few more epochs on the full dataset\n",
    "print(\"Fine-tuning last half of layers on full dataset with small learning rate...\")\n",
    "finetune_losses = train_one_stage(convnext, full_loader, finetune_optimizer, criterion, device, num_epochs=5, stage_name=\"Finetune_Half\")\n",
    "train_losses.extend(finetune_losses)\n",
    "\n",
    "# Save checkpoint after fine-tuning\n",
    "save_checkpoint(convnext, finetune_optimizer, train_losses, \"curriculum_checkpoint_finetune_half.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ef8e2c",
   "metadata": {},
   "source": [
    "## 12. Evaluate on test dataset and save submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e14055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = GalaxyZooTensorDataset(csv_dir=None, tensor_dir='./images_test_rev1/images_test_resized')\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "convnext.eval()\n",
    "all_predictions = []\n",
    "all_galaxy_ids = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, galaxy_ids in test_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        outputs = convnext(images)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        all_predictions.append(probs.cpu().numpy())\n",
    "        all_galaxy_ids.extend(galaxy_ids)\n",
    "\n",
    "predictions = np.concatenate(all_predictions, axis=0)\n",
    "\n",
    "columns = ['GalaxyId']\n",
    "questions = {1: 3, 2: 2, 3: 2, 4: 2, 5: 4, 6: 2, 7: 3, 8: 7, 9: 3, 10: 3, 11: 6}\n",
    "for q, count in questions.items():\n",
    "    for i in range(1, count + 1):\n",
    "        columns.append(f'Class{q}.{i}')\n",
    "\n",
    "submission_df = pd.DataFrame(predictions, columns=columns[1:])\n",
    "submission_df.insert(0, 'GalaxyId', all_galaxy_ids)\n",
    "print(submission_df.head())\n",
    "submission_df.to_csv('submission_curriculum.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
