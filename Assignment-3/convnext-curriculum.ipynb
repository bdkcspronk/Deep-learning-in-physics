{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d7e1ed6",
   "metadata": {},
   "source": [
    "# Galaxy Zoo 2: ConvNeXt Curriculum Learning\n",
    "\n",
    "This notebook demonstrates curriculum learning for the Galaxy Zoo 2 dataset using PyTorch and ConvNeXt. We reuse functions and classes from the original ConvNeXt notebook and implement a staged training process where the model is first trained on high-confidence examples, then gradually exposed to more ambiguous data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f659c6f",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries and Utilities\n",
    "Import all necessary libraries, including torch, torchvision, numpy, pandas, matplotlib, and any utility functions/classes reused from the original notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edc047fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:22:05.514067Z",
     "iopub.status.busy": "2026-02-27T14:22:05.513756Z",
     "iopub.status.idle": "2026-02-27T14:22:13.157159Z",
     "shell.execute_reply": "2026-02-27T14:22:13.156585Z",
     "shell.execute_reply.started": "2026-02-27T14:22:05.514030Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "import concurrent.futures\n",
    "from torchvision.models import ConvNeXt_Small_Weights\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8402e71a",
   "metadata": {},
   "source": [
    "## 2. Define Image Preprocessing and Tensor Saving Functions\n",
    "Reuse the image preprocessing and tensor saving functions from the original notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "857b0eee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:22:16.233833Z",
     "iopub.status.busy": "2026-02-27T14:22:16.233228Z",
     "iopub.status.idle": "2026-02-27T14:22:16.241193Z",
     "shell.execute_reply": "2026-02-27T14:22:16.240333Z",
     "shell.execute_reply.started": "2026-02-27T14:22:16.233801Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "norm = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "def process_image(img_path_output_size):\n",
    "    img_path, output_dir, size = img_path_output_size\n",
    "    basename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    out_path = os.path.join(output_dir, f\"{basename}.pt\")\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    width, height = img.size\n",
    "    left, top, right, bottom = 20, 20, width - 20, height - 20\n",
    "    img_cropped = img.crop((left, top, right, bottom))\n",
    "    img_resized = img_cropped.resize(size, Image.LANCZOS)\n",
    "    tensor = transforms.ToTensor()(img_resized)\n",
    "    tensor = norm(tensor)\n",
    "    torch.save(tensor, out_path)\n",
    "\n",
    "def save_tensor_images_threaded(input_dir, output_dir, size=(224, 224), num_workers=4):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    image_files = glob.glob(os.path.join(input_dir, '*.jpg'))\n",
    "    print(f\"Found {len(image_files)} images.\")\n",
    "    args = [(img_path, output_dir, size) for img_path in image_files]\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        results = list(executor.map(process_image, args))\n",
    "    for res in results[:20]:\n",
    "        print(res)\n",
    "    print(f\"Finished saving tensors for {len(image_files)} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "191bc735-afad-4695-b96a-fdab8e85eac7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T11:47:53.033647Z",
     "iopub.status.busy": "2026-02-27T11:47:53.033366Z",
     "iopub.status.idle": "2026-02-27T11:48:30.249460Z",
     "shell.execute_reply": "2026-02-27T11:48:30.248488Z",
     "shell.execute_reply.started": "2026-02-27T11:47:53.033627Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "def unzip_file(zip_path, extract_to):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "base_path = \"/kaggle/input/competitions/galaxy-zoo-the-galaxy-challenge\"\n",
    "output_path = \"/kaggle/working/galaxy_zoo\"\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "unzip_file(f\"{base_path}/images_training_rev1.zip\", output_path)\n",
    "unzip_file(f\"{base_path}/images_test_rev1.zip\", output_path)\n",
    "unzip_file(f\"{base_path}/training_solutions_rev1.zip\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "115b08ce-80da-4ce8-a6d2-d653fd2de30e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:22:29.020450Z",
     "iopub.status.busy": "2026-02-27T14:22:29.019782Z",
     "iopub.status.idle": "2026-02-27T14:22:29.024599Z",
     "shell.execute_reply": "2026-02-27T14:22:29.023847Z",
     "shell.execute_reply.started": "2026-02-27T14:22:29.020424Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.CenterCrop(384),   # replaces manual crop\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd76db",
   "metadata": {},
   "source": [
    "## 3. Define GalaxyZooTensorDataset Class\n",
    "Reuse the GalaxyZooTensorDataset class for loading preprocessed tensor images and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc42f218",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:22:31.762998Z",
     "iopub.status.busy": "2026-02-27T14:22:31.762356Z",
     "iopub.status.idle": "2026-02-27T14:22:31.769575Z",
     "shell.execute_reply": "2026-02-27T14:22:31.768809Z",
     "shell.execute_reply.started": "2026-02-27T14:22:31.762970Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GalaxyZooImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        if csv_file is not None:\n",
    "            self.df = pd.read_csv(csv_file)\n",
    "            self.ids = self.df.iloc[:, 0].values\n",
    "            self.labels = self.df.iloc[:, 1:].values.astype(np.float32)\n",
    "            self.has_labels = True\n",
    "        else:\n",
    "            self.df = None\n",
    "            self.ids = [\n",
    "                os.path.splitext(f)[0]\n",
    "                for f in os.listdir(image_dir)\n",
    "                if f.endswith(\".jpg\")\n",
    "            ]\n",
    "            self.labels = None\n",
    "            self.has_labels = False\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        galaxy_id = self.ids[idx]\n",
    "        img_path = os.path.join(self.image_dir, f\"{galaxy_id}.jpg\")\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.has_labels:\n",
    "            label = torch.tensor(self.labels[idx])\n",
    "            return image, label\n",
    "        else:\n",
    "            return image, galaxy_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425e4d2b",
   "metadata": {},
   "source": [
    "## 4. Prepare Curriculum Learning Data Splits\n",
    "We will split the training data into curriculum stages based on label confidence (maximum probability per sample). High-confidence samples will be used first, followed by medium and low-confidence samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "247c9013",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:22:34.991918Z",
     "iopub.status.busy": "2026-02-27T14:22:34.991175Z",
     "iopub.status.idle": "2026-02-27T14:22:35.245355Z",
     "shell.execute_reply": "2026-02-27T14:22:35.244682Z",
     "shell.execute_reply.started": "2026-02-27T14:22:34.991888Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High confidence: 20107 samples\n",
      "Medium confidence: 21556 samples\n",
      "Low confidence: 19915 samples\n"
     ]
    }
   ],
   "source": [
    "# Load training solutions and dataset\n",
    "csv_file = '/kaggle/working/galaxy_zoo/training_solutions_rev1.csv'\n",
    "image_dir = '/kaggle/working/galaxy_zoo/images_training_rev1'\n",
    "dataset = GalaxyZooImageDataset(csv_file, image_dir, transform=train_transform)\n",
    "\n",
    "# Compute confidence (max probability) for each sample\n",
    "confidences = dataset.labels.max(axis=1)\n",
    "\n",
    "# Define thresholds for curriculum stages\n",
    "high_thresh = 0.94\n",
    "med_thresh = 0.85\n",
    "\n",
    "high_conf_idx = np.where(confidences >= high_thresh)[0]\n",
    "med_conf_idx = np.where((confidences < high_thresh) & (confidences >= med_thresh))[0]\n",
    "low_conf_idx = np.where(confidences < med_thresh)[0]\n",
    "\n",
    "print(f\"High confidence: {len(high_conf_idx)} samples\")\n",
    "print(f\"Medium confidence: {len(med_conf_idx)} samples\")\n",
    "print(f\"Low confidence: {len(low_conf_idx)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a733c0e6",
   "metadata": {},
   "source": [
    "## 5. Create DataLoaders for Curriculum Stages\n",
    "Create DataLoaders for each curriculum stage using the corresponding subset of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9eb57d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:22:38.949695Z",
     "iopub.status.busy": "2026-02-27T14:22:38.949047Z",
     "iopub.status.idle": "2026-02-27T14:22:38.978004Z",
     "shell.execute_reply": "2026-02-27T14:22:38.977311Z",
     "shell.execute_reply.started": "2026-02-27T14:22:38.949666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "high_conf_loader = DataLoader(Subset(dataset, high_conf_idx), batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "med_conf_loader = DataLoader(Subset(dataset, np.concatenate([high_conf_idx, med_conf_idx])), batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "full_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "# For validation, split a portion from the full dataset\n",
    "from torch.utils.data import random_split\n",
    "total = len(dataset)\n",
    "val_size = int(0.2 * total)\n",
    "train_size = total - val_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60b2f39",
   "metadata": {},
   "source": [
    "## 6. Load and Modify ConvNeXt Model\n",
    "Load the ConvNeXt model, freeze all layers except the classifier, and modify the final layer to match the number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7df0233",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T13:50:54.932876Z",
     "iopub.status.busy": "2026-02-27T13:50:54.932486Z",
     "iopub.status.idle": "2026-02-27T13:50:57.355522Z",
     "shell.execute_reply": "2026-02-27T13:50:57.354332Z",
     "shell.execute_reply.started": "2026-02-27T13:50:54.932846Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision.models import convnext_small, ConvNeXt_Small_Weights\n",
    "convnext = models.convnext_small(weights=ConvNeXt_Small_Weights.IMAGENET1K_V1)\n",
    "num_classes = dataset.labels.shape[1]\n",
    "\n",
    "# Freeze everything first\n",
    "for param in convnext.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final classifier layer\n",
    "in_features = convnext.classifier[2].in_features\n",
    "convnext.classifier[2] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "# Unfreeze last two feature stages and classifier, collect params for optimizer\n",
    "backbone_params = []\n",
    "classifier_params = []\n",
    "\n",
    "for stage in convnext.features[-2:]:\n",
    "    for param in stage.parameters():\n",
    "        param.requires_grad = True\n",
    "        backbone_params.append(param)\n",
    "\n",
    "for param in convnext.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "    classifier_params.append(param)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "convnext = convnext.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13479e4",
   "metadata": {},
   "source": [
    "## 7. Set Up Loss Function and Optimizer\n",
    "Set up the BCEWithLogitsLoss and Adam optimizer, filtering parameters as in the original notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22470481",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:22:46.382644Z",
     "iopub.status.busy": "2026-02-27T14:22:46.382029Z",
     "iopub.status.idle": "2026-02-27T14:22:46.389198Z",
     "shell.execute_reply": "2026-02-27T14:22:46.388278Z",
     "shell.execute_reply.started": "2026-02-27T14:22:46.382618Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [\n",
    "        {\"params\": backbone_params, \"lr\": 1e-4},\n",
    "        {\"params\": classifier_params, \"lr\": 1e-3},\n",
    "    ],\n",
    "    weight_decay=1e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378a073c",
   "metadata": {},
   "source": [
    "## 8. Train Model with Curriculum Learning Loop\n",
    "Train the model sequentially on high-confidence, then medium, then all data. Track and print training loss for each stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcfea4e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:22:59.967602Z",
     "iopub.status.busy": "2026-02-27T14:22:59.967283Z",
     "iopub.status.idle": "2026-02-27T14:22:59.974219Z",
     "shell.execute_reply": "2026-02-27T14:22:59.973568Z",
     "shell.execute_reply.started": "2026-02-27T14:22:59.967576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_one_stage(model, loader, optimizer, criterion, device, num_epochs=3, stage_name=\"Stage\"):\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        for batch_idx, (images, labels) in enumerate(loader):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            # Debug every 30 batches\n",
    "            if (batch_idx + 1) % 30 == 0:\n",
    "                current_avg = running_loss / ((batch_idx + 1) * loader.batch_size)\n",
    "                print(\n",
    "                    f\"{stage_name} Epoch {epoch+1}/{num_epochs} \"\n",
    "                    f\"Batch {batch_idx+1}/{len(loader)} \"\n",
    "                    f\"Loss={loss.item():.4f} \"\n",
    "                    f\"RunningAvg={current_avg:.4f}\"\n",
    "                )\n",
    "\n",
    "        avg_loss = running_loss / len(loader.dataset)\n",
    "        losses.append(avg_loss)\n",
    "\n",
    "        print(\n",
    "            f\"{stage_name} Epoch {epoch+1}/{num_epochs}: \"\n",
    "            f\"Loss={avg_loss:.4f}, \"\n",
    "            f\"Time={time.time()-epoch_start:.2f}s\"\n",
    "        )\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2bc55e",
   "metadata": {},
   "source": [
    "## 9. Save Model Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fff9f4b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:23:02.760472Z",
     "iopub.status.busy": "2026-02-27T14:23:02.759817Z",
     "iopub.status.idle": "2026-02-27T14:23:02.764187Z",
     "shell.execute_reply": "2026-02-27T14:23:02.763608Z",
     "shell.execute_reply.started": "2026-02-27T14:23:02.760448Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, train_losses, filename):\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_losses': train_losses\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "    print(f\"Checkpoint saved as {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98907160",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T14:23:05.384561Z",
     "iopub.status.busy": "2026-02-27T14:23:05.383828Z",
     "iopub.status.idle": "2026-02-27T14:23:05.387675Z",
     "shell.execute_reply": "2026-02-27T14:23:05.387042Z",
     "shell.execute_reply.started": "2026-02-27T14:23:05.384508Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bf45e81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T11:48:32.924004Z",
     "iopub.status.busy": "2026-02-27T11:48:32.923799Z",
     "iopub.status.idle": "2026-02-27T12:03:11.263298Z",
     "shell.execute_reply": "2026-02-27T12:03:11.262651Z",
     "shell.execute_reply.started": "2026-02-27T11:48:32.923985Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on high-confidence samples...\n",
      "High_Confidence_2_layers Epoch 1/5 Batch 30/40 Loss=0.2506 RunningAvg=0.3088\n",
      "High_Confidence_2_layers Epoch 1/5: Loss=0.2934, Time=177.72s\n",
      "High_Confidence_2_layers Epoch 2/5 Batch 30/40 Loss=0.2336 RunningAvg=0.2334\n",
      "High_Confidence_2_layers Epoch 2/5: Loss=0.2325, Time=174.37s\n",
      "High_Confidence_2_layers Epoch 3/5 Batch 30/40 Loss=0.2227 RunningAvg=0.2241\n",
      "High_Confidence_2_layers Epoch 3/5: Loss=0.2237, Time=175.42s\n",
      "High_Confidence_2_layers Epoch 4/5 Batch 30/40 Loss=0.2258 RunningAvg=0.2205\n",
      "High_Confidence_2_layers Epoch 4/5: Loss=0.2201, Time=174.97s\n",
      "High_Confidence_2_layers Epoch 5/5 Batch 30/40 Loss=0.2152 RunningAvg=0.2179\n",
      "High_Confidence_2_layers Epoch 5/5: Loss=0.2171, Time=175.49s\n",
      "Checkpoint saved as curriculum_checkpoint_High_Confidence_2_layers.pth\n"
     ]
    }
   ],
   "source": [
    "print(\"Training on high-confidence samples...\")\n",
    "stage_name = \"High_Confidence_2_layers\"\n",
    "high_losses = train_one_stage(convnext, high_conf_loader, optimizer, criterion, device, num_epochs=5, stage_name=stage_name)\n",
    "save_checkpoint(convnext, optimizer, train_losses, f\"curriculum_checkpoint_{stage_name}.pth\")\n",
    "train_losses.extend(high_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bca3bec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T12:03:11.264746Z",
     "iopub.status.busy": "2026-02-27T12:03:11.264316Z",
     "iopub.status.idle": "2026-02-27T12:33:29.038423Z",
     "shell.execute_reply": "2026-02-27T12:33:29.037645Z",
     "shell.execute_reply.started": "2026-02-27T12:03:11.264713Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on high+medium-confidence samples...\n",
      "Medium_Confidence_2_layers Epoch 1/5 Batch 30/82 Loss=0.2317 RunningAvg=0.2342\n",
      "Medium_Confidence_2_layers Epoch 1/5 Batch 60/82 Loss=0.2283 RunningAvg=0.2342\n",
      "Medium_Confidence_2_layers Epoch 1/5: Loss=0.2340, Time=364.33s\n",
      "Medium_Confidence_2_layers Epoch 2/5 Batch 30/82 Loss=0.2293 RunningAvg=0.2323\n",
      "Medium_Confidence_2_layers Epoch 2/5 Batch 60/82 Loss=0.2304 RunningAvg=0.2324\n",
      "Medium_Confidence_2_layers Epoch 2/5: Loss=0.2322, Time=363.03s\n",
      "Medium_Confidence_2_layers Epoch 3/5 Batch 30/82 Loss=0.2351 RunningAvg=0.2319\n",
      "Medium_Confidence_2_layers Epoch 3/5 Batch 60/82 Loss=0.2302 RunningAvg=0.2308\n",
      "Medium_Confidence_2_layers Epoch 3/5: Loss=0.2307, Time=363.43s\n",
      "Medium_Confidence_2_layers Epoch 4/5 Batch 30/82 Loss=0.2266 RunningAvg=0.2296\n",
      "Medium_Confidence_2_layers Epoch 4/5 Batch 60/82 Loss=0.2360 RunningAvg=0.2293\n",
      "Medium_Confidence_2_layers Epoch 4/5: Loss=0.2293, Time=363.34s\n",
      "Medium_Confidence_2_layers Epoch 5/5 Batch 30/82 Loss=0.2291 RunningAvg=0.2287\n",
      "Medium_Confidence_2_layers Epoch 5/5 Batch 60/82 Loss=0.2232 RunningAvg=0.2286\n",
      "Medium_Confidence_2_layers Epoch 5/5: Loss=0.2287, Time=363.30s\n",
      "Checkpoint saved as curriculum_checkpoint_Medium_Confidence_2_layers.pth\n"
     ]
    }
   ],
   "source": [
    "print(\"Training on high+medium-confidence samples...\")\n",
    "stage_name = \"Medium_Confidence_2_layers\"\n",
    "med_losses = train_one_stage(convnext, med_conf_loader, optimizer, criterion, device, num_epochs=5, stage_name=stage_name)\n",
    "save_checkpoint(convnext, optimizer, train_losses, f\"curriculum_checkpoint_{stage_name}.pth\")\n",
    "train_losses.extend(med_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35d4ecbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T12:33:29.039749Z",
     "iopub.status.busy": "2026-02-27T12:33:29.039514Z",
     "iopub.status.idle": "2026-02-27T13:30:19.488732Z",
     "shell.execute_reply": "2026-02-27T13:30:19.487911Z",
     "shell.execute_reply.started": "2026-02-27T12:33:29.039728Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on all samples...\n",
      "All_data_2_layers Epoch 1/10 Batch 30/121 Loss=0.2431 RunningAvg=0.2470\n",
      "All_data_2_layers Epoch 1/10 Batch 60/121 Loss=0.2483 RunningAvg=0.2467\n",
      "All_data_2_layers Epoch 1/10 Batch 90/121 Loss=0.2468 RunningAvg=0.2465\n",
      "All_data_2_layers Epoch 1/10 Batch 120/121 Loss=0.2513 RunningAvg=0.2465\n",
      "All_data_2_layers Epoch 1/10: Loss=0.2465, Time=343.20s\n",
      "All_data_2_layers Epoch 2/10 Batch 30/121 Loss=0.2460 RunningAvg=0.2454\n",
      "All_data_2_layers Epoch 2/10 Batch 60/121 Loss=0.2397 RunningAvg=0.2453\n",
      "All_data_2_layers Epoch 2/10 Batch 90/121 Loss=0.2391 RunningAvg=0.2454\n",
      "All_data_2_layers Epoch 2/10 Batch 120/121 Loss=0.2490 RunningAvg=0.2455\n",
      "All_data_2_layers Epoch 2/10: Loss=0.2455, Time=340.73s\n",
      "All_data_2_layers Epoch 3/10 Batch 30/121 Loss=0.2490 RunningAvg=0.2443\n",
      "All_data_2_layers Epoch 3/10 Batch 60/121 Loss=0.2450 RunningAvg=0.2449\n",
      "All_data_2_layers Epoch 3/10 Batch 90/121 Loss=0.2416 RunningAvg=0.2451\n",
      "All_data_2_layers Epoch 3/10 Batch 120/121 Loss=0.2463 RunningAvg=0.2448\n",
      "All_data_2_layers Epoch 3/10: Loss=0.2448, Time=340.18s\n",
      "All_data_2_layers Epoch 4/10 Batch 30/121 Loss=0.2415 RunningAvg=0.2437\n",
      "All_data_2_layers Epoch 4/10 Batch 60/121 Loss=0.2462 RunningAvg=0.2441\n",
      "All_data_2_layers Epoch 4/10 Batch 90/121 Loss=0.2468 RunningAvg=0.2441\n",
      "All_data_2_layers Epoch 4/10 Batch 120/121 Loss=0.2452 RunningAvg=0.2441\n",
      "All_data_2_layers Epoch 4/10: Loss=0.2442, Time=340.82s\n",
      "All_data_2_layers Epoch 5/10 Batch 30/121 Loss=0.2528 RunningAvg=0.2438\n",
      "All_data_2_layers Epoch 5/10 Batch 60/121 Loss=0.2472 RunningAvg=0.2437\n",
      "All_data_2_layers Epoch 5/10 Batch 90/121 Loss=0.2426 RunningAvg=0.2436\n",
      "All_data_2_layers Epoch 5/10 Batch 120/121 Loss=0.2394 RunningAvg=0.2437\n",
      "All_data_2_layers Epoch 5/10: Loss=0.2437, Time=340.98s\n",
      "All_data_2_layers Epoch 6/10 Batch 30/121 Loss=0.2452 RunningAvg=0.2444\n",
      "All_data_2_layers Epoch 6/10 Batch 60/121 Loss=0.2438 RunningAvg=0.2439\n",
      "All_data_2_layers Epoch 6/10 Batch 90/121 Loss=0.2418 RunningAvg=0.2435\n",
      "All_data_2_layers Epoch 6/10 Batch 120/121 Loss=0.2432 RunningAvg=0.2433\n",
      "All_data_2_layers Epoch 6/10: Loss=0.2433, Time=340.80s\n",
      "All_data_2_layers Epoch 7/10 Batch 30/121 Loss=0.2443 RunningAvg=0.2427\n",
      "All_data_2_layers Epoch 7/10 Batch 60/121 Loss=0.2388 RunningAvg=0.2430\n",
      "All_data_2_layers Epoch 7/10 Batch 90/121 Loss=0.2436 RunningAvg=0.2428\n",
      "All_data_2_layers Epoch 7/10 Batch 120/121 Loss=0.2414 RunningAvg=0.2429\n",
      "All_data_2_layers Epoch 7/10: Loss=0.2429, Time=341.24s\n",
      "All_data_2_layers Epoch 8/10 Batch 30/121 Loss=0.2460 RunningAvg=0.2425\n",
      "All_data_2_layers Epoch 8/10 Batch 60/121 Loss=0.2409 RunningAvg=0.2426\n",
      "All_data_2_layers Epoch 8/10 Batch 90/121 Loss=0.2447 RunningAvg=0.2425\n",
      "All_data_2_layers Epoch 8/10 Batch 120/121 Loss=0.2372 RunningAvg=0.2424\n",
      "All_data_2_layers Epoch 8/10: Loss=0.2424, Time=341.25s\n",
      "All_data_2_layers Epoch 9/10 Batch 30/121 Loss=0.2405 RunningAvg=0.2413\n",
      "All_data_2_layers Epoch 9/10 Batch 60/121 Loss=0.2434 RunningAvg=0.2418\n",
      "All_data_2_layers Epoch 9/10 Batch 90/121 Loss=0.2426 RunningAvg=0.2421\n",
      "All_data_2_layers Epoch 9/10 Batch 120/121 Loss=0.2460 RunningAvg=0.2421\n",
      "All_data_2_layers Epoch 9/10: Loss=0.2421, Time=340.51s\n",
      "All_data_2_layers Epoch 10/10 Batch 30/121 Loss=0.2435 RunningAvg=0.2425\n",
      "All_data_2_layers Epoch 10/10 Batch 60/121 Loss=0.2436 RunningAvg=0.2423\n",
      "All_data_2_layers Epoch 10/10 Batch 90/121 Loss=0.2402 RunningAvg=0.2416\n",
      "All_data_2_layers Epoch 10/10 Batch 120/121 Loss=0.2387 RunningAvg=0.2417\n",
      "All_data_2_layers Epoch 10/10: Loss=0.2417, Time=340.38s\n",
      "Checkpoint saved as curriculum_checkpoint_All_data_2_layers.pth\n"
     ]
    }
   ],
   "source": [
    "print(\"Training on all samples...\")\n",
    "stage_name = \"All_data_2_layers\"\n",
    "full_losses = train_one_stage(convnext, full_loader, optimizer, criterion, device, num_epochs=10, stage_name=stage_name)\n",
    "save_checkpoint(convnext, optimizer, train_losses, f\"curriculum_checkpoint_{stage_name}.pth\")\n",
    "train_losses.extend(full_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f18934c",
   "metadata": {},
   "source": [
    "## 10. Save Training Loss for Each Curriculum Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7ec9416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T13:30:19.490304Z",
     "iopub.status.busy": "2026-02-27T13:30:19.490037Z",
     "iopub.status.idle": "2026-02-27T13:30:19.502140Z",
     "shell.execute_reply": "2026-02-27T13:30:19.501540Z",
     "shell.execute_reply.started": "2026-02-27T13:30:19.490278Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training losses saved to curriculum_train_losses_2_layers.csv\n"
     ]
    }
   ],
   "source": [
    "loss_df = pd.DataFrame({'epoch': list(range(1, len(train_losses)+1)), 'loss': train_losses})\n",
    "loss_df.to_csv('curriculum_train_losses_2_layers.csv', index=False)\n",
    "print('Training losses saved to curriculum_train_losses_2_layers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ef8e2c",
   "metadata": {},
   "source": [
    "## 11. Evaluate on test dataset and save submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e14055e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-02-27T14:15:41.638592Z",
     "iopub.status.idle": "2026-02-27T14:15:41.638964Z",
     "shell.execute_reply": "2026-02-27T14:15:41.638779Z",
     "shell.execute_reply.started": "2026-02-27T14:15:41.638762Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = GalaxyZooImageDataset(\n",
    "    csv_file=None,\n",
    "    image_dir='/kaggle/working/galaxy_zoo/images_test_rev1',\n",
    "    transform=train_transform\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "convnext.eval()\n",
    "all_predictions = []\n",
    "all_galaxy_ids = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, galaxy_ids in test_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        outputs = convnext(images)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        all_predictions.append(probs.cpu().numpy())\n",
    "        all_galaxy_ids.extend(galaxy_ids)\n",
    "\n",
    "predictions = np.concatenate(all_predictions, axis=0)\n",
    "\n",
    "columns = ['GalaxyId']\n",
    "questions = {1: 3, 2: 2, 3: 2, 4: 2, 5: 4, 6: 2, 7: 3, 8: 7, 9: 3, 10: 3, 11: 6}\n",
    "for q, count in questions.items():\n",
    "    for i in range(1, count + 1):\n",
    "        columns.append(f'Class{q}.{i}')\n",
    "\n",
    "submission_df = pd.DataFrame(predictions, columns=columns[1:])\n",
    "submission_df.insert(0, 'GalaxyId', all_galaxy_ids)\n",
    "print(submission_df.head())\n",
    "submission_df.to_csv('submission_curriculum_2_layer.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 44352,
     "sourceId": 3175,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31286,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
